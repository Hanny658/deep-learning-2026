{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ntu-dl-bootcamp/deep-learning-2025/blob/main/SESSION2/session2_part2.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Datasets and DataLoaders in PyTorch\n",
        "\n",
        "| Component      | Purpose                                                                 | Think of it as...                                   |\n",
        "|----------------|-------------------------------------------------------------------------|-----------------------------------------------------|\n",
        "| **Dataset**     | Stores the data and labels, and knows how to return **one sample**      | A **bookshelf** full of data                        |\n",
        "| **DataLoader**  | Efficiently provides the data to the model in **mini-batches**, optionally **shuffled** | A **librarian** handing small stacks of books to you |\n",
        "\n",
        "When training a deep learning model, we typically work with many samples (e.g., thousands of images). We do **not** feed all samples to the model at once. Instead, we train using **mini-batches** (small groups of samples per step).\n",
        "\n",
        "PyTorch provides many ready-to-use datasets:\n",
        "\n",
        "- **Image:** https://pytorch.org/vision/stable/datasets.html  \n",
        "- **Text:** https://pytorch.org/text/stable/datasets.html  \n",
        "- **Audio:** https://pytorch.org/audio/stable/datasets.html\n",
        "\n",
        "<div style=\"border: 2px solid #4A90E2; padding: 10px; border-radius: 6px\">\n",
        "<strong> ðŸš© Question:</strong> Why don't we feed all the samples to the model at once?\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWxqggWBX1cB"
      },
      "source": [
        "## Loading a Dataset\n",
        "\n",
        "The **MNIST** (Modified National Institute of Standards and Technology) dataset is a classic benchmark dataset of handwritten digits used widely in machine learning and deep learning.\n",
        "\n",
        "Each image in the dataset is:\n",
        "\n",
        "- **28 Ã— 28** pixels (grayscale)\n",
        "- **Labeled** with a digit **0â€“9**\n",
        "- Part of a collection of **70,000 images**  \n",
        "  - **60,000** for training  \n",
        "  - **10,000** for testing  \n",
        "\n",
        "Because the images are small and simple, MNIST is ideal for learning the basics of building and training neural networks.\n",
        "\n",
        "We will load MNIST using `torchvision.datasets`.  \n",
        "More details here: https://en.wikipedia.org/wiki/MNIST_database\n",
        "\n",
        "<div style=\"border: 2px solid #4A90E2; padding: 10px; border-radius: 6px\">\n",
        "<strong>What does a PyTorch Dataset contain?</strong>\n",
        "\n",
        "- The **input samples** (in this case, images of digits)\n",
        "- The corresponding **labels** (which digit each image represents)\n",
        "- A method to retrieve a **single** example at a time:  \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wvWcdvSOVxjU"
      },
      "outputs": [],
      "source": [
        "# Import the necessary modules from torchvision\n",
        "from torchvision import datasets  # for accessing popular datasets\n",
        "from torchvision.transforms import ToTensor  # for converting images to PyTorch tensors\n",
        "\n",
        "# Download and prepare the training data\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",  # 'root' is the directory where the dataset will be stored\n",
        "    train=True,  # 'train=True' specifies that we want the training set\n",
        "    download=True,  # 'download=True' will download the dataset if it's not already present\n",
        "    transform=ToTensor(),  # 'transform=ToTensor()' converts the images to PyTorch tensors (needed for PyTorch models)\n",
        ")\n",
        "\n",
        "# Download and prepare the test data\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",  # Store the test data in the same directory as training data\n",
        "    train=False,  # 'train=False' specifies that we want the test set\n",
        "    download=True,  # 'download=True' will download the test dataset if it's not already present\n",
        "    transform=ToTensor(),  # Convert test images to tensors, just like the training data\n",
        ")\n",
        "\n",
        "# Explanation:\n",
        "# - datasets.MNIST() provides access to the MNIST dataset, with options to load either training or test data.\n",
        "# - ToTensor() transforms each image from a PIL image format (used by default) to a PyTorch tensor.\n",
        "# - The 'root' parameter specifies where the data should be saved on your system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84rMBLuMZfJD",
        "outputId": "9ea3911a-776e-43cf-baa1-f95cbe167b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in training data  60000\n",
            "Number of samples in test data  10000\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of samples in training data \", len(training_data))\n",
        "print(\"Number of samples in test data \", len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63vl9X_hbHP0",
        "outputId": "4abd0c7c-8306-40f3-ba80-ec388c082079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image shape before np.squeeze: torch.Size([1, 28, 28])\n",
            "Image shape before np.squeeze: torch.Size([28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Import the necessary module for plotting images\n",
        "import matplotlib.pyplot as plt  # 'matplotlib.pyplot' is a library for creating visualizations in Python\n",
        "\n",
        "# Access the 10th image and its label from the training dataset\n",
        "image, label = training_data[\n",
        "    10\n",
        "]  # 'training_data[10]' retrieves the 9th image and its label from the dataset\n",
        "\n",
        "# Print the shape of the image tensor\n",
        "print(\n",
        "    f\"Image shape before np.squeeze: {image.shape}\"\n",
        ")  # dimensions of the image tensor before any modifications\n",
        "\n",
        "# Remove the single color channel dimension from the image tensor\n",
        "image = (\n",
        "    image.squeeze()\n",
        ")  # 'squeeze()' removes extra dimensions of size 1 (from [1, 28, 28] to [28, 28])\n",
        "\n",
        "# Print the shape of the image tensor after squeezing\n",
        "print(f\"Image shape before np.squeeze: {image.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "q88dR3tfGBPV",
        "outputId": "d31c5021-4995-492f-aa5e-4cf766752ef7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 3\n"
          ]
        }
      ],
      "source": [
        "# Display the image using matplotlib\n",
        "plt.imshow(image, cmap=\"gray\")  # 'cmap='gray'' shows it in grayscale\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")\n",
        "\n",
        "# TODO: Try to visualise a different sample from the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border: 2px solid #4A90E2; padding: 10px; border-radius: 6px\">\n",
        "<strong> ðŸš© TODO</strong>\n",
        "Try to visualise a different sample from the dataset \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_IJ3lSGbjrb"
      },
      "source": [
        "## Preparing Your Data for Use in a Model Using DataLoaders\n",
        "\n",
        "The `Dataset` we created above gives us **one sample at a time**.  \n",
        "But when training a neural network, we usually don't feed samples one-by-one. Instead, we want to:\n",
        "\n",
        "1. **Group samples into mini-batches** (so the model sees several examples at once)\n",
        "2. **Shuffle** the samples (more on this later)\n",
        "3. **Load data efficiently**, possibly using multiple CPU cores\n",
        "\n",
        "A **DataLoader** is an _iterable_ that takes a `Dataset` and handles all of this automatically.  \n",
        "It prepares mini-batches for us, shuffles when needed, and can speed up data loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D_VIlqzFaqT5"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D9vtcvndAwr"
      },
      "source": [
        "We have loaded our dataset into a `DataLoader`, which allows us to iterate through the data in **batches**. Each iteration returns a batch of `train_features` and `train_labels`.\n",
        "\n",
        "If `shuffle=True` was set in the `DataLoader`, then the order of the data will **be shuffled the next time we iterate over it**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxJFfJQUcruN",
        "outputId": "ad8096dd-5c8b-4ea5-cd32-ea1c71870961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "p4KwSlkRdquy",
        "outputId": "23c4d738-5471-4a8d-a229-621c841c3c20"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 1\n"
          ]
        }
      ],
      "source": [
        "# Visualising one image from the selected batch\n",
        "\n",
        "img = train_features[10].squeeze()\n",
        "label = train_labels[10]\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")\n",
        "\n",
        "# TODO: Try to visualise a different sample from this batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border: 2px solid #4A90E2; padding: 10px; border-radius: 6px\">\n",
        "<strong> ðŸš© TODO</strong>\n",
        "Try to visualise a different sample from this batch \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izv4-F3He1Og"
      },
      "source": [
        "# Build the Neural Network\n",
        "\n",
        "A **neural network** is made up of layers that transform the input data step by step.  \n",
        "\n",
        "PyTorch provides these layers and building blocks inside the `torch.nn` module.\n",
        "\n",
        "In PyTorch, every neural network component is written as a **class** that inherits from `nn.Module`.  \n",
        "This includes:\n",
        "\n",
        "- Individual layers (e.g., `nn.Linear`, `nn.Conv2d`)\n",
        "- Activation functions (e.g., `nn.ReLU`)\n",
        "- Even entire neural networks\n",
        "\n",
        "A neural network is therefore just a **module made up of other modules**.  \n",
        "This **nested structure** makes it easy to build simple or very complex models by combining layers like building blocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0fNQrmFyflkz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW80AIgEftUZ",
        "outputId": "d50a2ad2-cbed-48d6-bc3a-4d373531d388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "# check if GPU is availble\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beH1p35uG2dm"
      },
      "source": [
        "<div style=\"border: 2px solid #4A90E2; padding: 10px; border-radius: 6px;\">\n",
        "<strong>ðŸš© Note:</strong>  \n",
        "If your output shows <em>\"Using cpu device\"</em>, your notebook is currently running on the CPU.  \n",
        "To speed up training, switch to a GPU.\n",
        "\n",
        "**In Google Colab:**\n",
        "1. Go to **Runtime** â†’ **Change runtime type**\n",
        "2. Set **Hardware accelerator** to **T4 GPU**\n",
        "3. Save and wait for Colab to restart\n",
        "4. Re-run all previous cells before continuing\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daZ_MXbjgjGU"
      },
      "source": [
        "Next, we define our model by creating a Python class that subclasses `nn.Module`.\n",
        "\n",
        "- In the `__init__` method, we **set up the layers** (the building blocks of the network).\n",
        "- In the `forward` method, we **describe how the input data flows through those layers**.\n",
        "\n",
        "In other words:\n",
        "\n",
        "`__init__` = *what components the network has*\n",
        "\n",
        "`forward` = *how those components are used to compute the output*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hyPYsmsZgKz6"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfhz_6KthZH0",
        "outputId": "534fe1e3-074c-42e6-be4d-a5978b3d6633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create an object of the model class and move that object to the `device` we\n",
        "# defined earlier\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "6seQ939Ehjki",
        "outputId": "5dbadcc9-d772-4ae5-cf0e-4b0c547ea7cc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 5\n",
            "\n",
            "Logits: tensor([[ 0.0004,  0.0715, -0.0012, -0.0244, -0.0051,  0.0175,  0.0288, -0.0787,\n",
            "         -0.0061,  0.0144]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Predicted probabilities: tensor([[0.0998, 0.1072, 0.0996, 0.0974, 0.0993, 0.1015, 0.1027, 0.0922, 0.0992,\n",
            "         0.1012]], grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "Predicted class: tensor([1])\n"
          ]
        }
      ],
      "source": [
        "# Take one sample from the dataset\n",
        "img, label = training_data[0]\n",
        "\n",
        "# Visualize the image\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\\n\")\n",
        "\n",
        "# Move the image to the same device as the model (CPU or GPU)\n",
        "img = img.to(device)\n",
        "\n",
        "# Run the image through the model (forward pass)\n",
        "logits = model(img)\n",
        "print(f\"Logits: {logits}\\n\")  # Raw, unnormalized class scores\n",
        "\n",
        "# Convert logits to probabilities\n",
        "predicted_probabilities = nn.Softmax(dim=1)(logits)\n",
        "print(f\"Predicted probabilities: {predicted_probabilities}\\n\")\n",
        "\n",
        "# Pick the class with the highest probability\n",
        "predicted_class = torch.argmax(predicted_probabilities, dim=1)\n",
        "print(f\"Predicted class: {predicted_class}\")\n",
        "\n",
        "# TODO: Try with another image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ4fwHiCm8A3"
      },
      "source": [
        "## What happens to the input at each layer in the network?\n",
        "\n",
        "To understand how data flows through our model, let's take a small **mini-batch** of 3 random images (each 28 Ã— 28) and pass them through the network layer by layer.\n",
        "\n",
        "This will help us see **how the shape of the data changes** at each step.\n",
        "\n",
        "Our model architecture:\n",
        "```\n",
        "NeuralNetwork(\n",
        "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
        "  (linear_relu_stack): Sequential(\n",
        "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
        "    (1): ReLU()\n",
        "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
        "    (3): ReLU()\n",
        "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
        "  )\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RJQy7-njEE6",
        "outputId": "8f60aac4-7092-4f85-8f4e-9c5025762024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Create a minibatch containing 3 random images of size 28 x 28\n",
        "input_minibatch = torch.rand(3, 28, 28)\n",
        "print(input_minibatch.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoVcmxHOoK61"
      },
      "source": [
        "### nn.Flatten\n",
        "\n",
        "Let us initialise a `nn.Flatten` module. It converts each 28 x 28 image into a contiguous array of 784 pixels each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXTPUy1cn-O0",
        "outputId": "0ec787bd-7508-4ec1-8094-5629fc99f9f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ],
      "source": [
        "flatten = nn.Flatten()  # initialise the flatten module\n",
        "flat_image = flatten(\n",
        "    input_minibatch\n",
        ")  # pass the input minibatch through the initialised module\n",
        "print(flat_image.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN94eOX1okRh"
      },
      "source": [
        "### nn.Linear\n",
        "\n",
        "The linear module applies a linear transformation to the input using its stored weights and biases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Ewd1lIoecJ",
        "outputId": "576cdcb1-d0ae-47c3-9e17-de16be5ed46f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 512])\n"
          ]
        }
      ],
      "source": [
        "layer1 = nn.Linear(in_features=28 * 28, out_features=512)  # initialise the linear layer\n",
        "hidden1 = layer1(\n",
        "    flat_image\n",
        ")  # pass the output from previous flatten layer through the linear layer\n",
        "print(hidden1.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uH_hKCCpIr0"
      },
      "source": [
        "## nn.ReLU\n",
        "\n",
        "Non-linear activation functions are what creates the complex mappings between the model's inputs and outputs. They are applied after linear transformations to introduce non-linearity.\n",
        "\n",
        "In this model, we use the `nn.ReLU` between our layers. There are other non-linear activation functions like `nn.Sigmoid` and `nn.Tanh`.\n",
        "\n",
        "Read more: [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html), [nn.Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html), [nn.Tanh](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37f4kWoIoztq",
        "outputId": "648cc173-665e-4584-cdb3-1b35947fcfc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before ReLU: tensor([[ 0.6862, -0.4041, -0.0984,  ..., -0.1117,  0.1717,  0.2071],\n",
            "        [ 0.6548, -0.5871,  0.0939,  ..., -0.0382, -0.0278,  0.2277],\n",
            "        [ 0.6584, -0.7966,  0.1020,  ..., -0.1625,  0.0478, -0.1559]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.6862, 0.0000, 0.0000,  ..., 0.0000, 0.1717, 0.2071],\n",
            "        [0.6548, 0.0000, 0.0939,  ..., 0.0000, 0.0000, 0.2277],\n",
            "        [0.6584, 0.0000, 0.1020,  ..., 0.0000, 0.0478, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "relu = nn.ReLU()\n",
        "hidden1 = relu(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")\n",
        "\n",
        "# TODO: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border: 2px solid #4A90E2; padding: 10px; border-radius: 6px;\">\n",
        "<strong>ðŸš© Note:</strong>  \n",
        "Notice what happened to the negative values in the input before they are passed through ReLU\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRAoOyPjqqTg"
      },
      "source": [
        "## nn.Sequential\n",
        "\n",
        "`nn.Sequential` is an **ordered** container of modules. The data is passed through all the modules in the same order as they are defined.\n",
        "\n",
        "You can use sequential containers to put together a **block** containing many layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2OVqUf_qaQU",
        "outputId": "aa7ca1b0-b8bf-4934-d092-b1a164bb335b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input mini batch: torch.Size([3, 28, 28])\n",
            "Logits: torch.Size([3, 10])\n"
          ]
        }
      ],
      "source": [
        "block1 = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(28 * 28, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 10),\n",
        ")\n",
        "\n",
        "input_image = torch.rand(3, 28, 28)\n",
        "print(f\"Input mini batch: {input_image.size()}\")\n",
        "logits = block1(input_image)\n",
        "print(f\"Logits: {logits.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gZyZOHcruCN"
      },
      "source": [
        "## nn.Softmax\n",
        "\n",
        "The last linear layer of the neural network returns logits. Logits are raw values in [-infty, +infty]. These logits are passed into the softmax module.\n",
        "\n",
        "Softmax scales the logits to [0, 1], representing the **model's predicted probabilities** for each class.\n",
        "\n",
        "`dim` parameter indicates the axis along which the values should sum to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT1HMvWZrf6F",
        "outputId": "a2e02852-7080-4468-f4f5-12fdd2712d15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logits\n",
            "tensor([[ 0.0696, -0.0505, -0.0651, -0.0145,  0.0016, -0.0058, -0.0144, -0.0516,\n",
            "         -0.0174,  0.0294],\n",
            "        [ 0.0684, -0.0396, -0.0291, -0.0180, -0.0501, -0.0105,  0.0007, -0.0492,\n",
            "         -0.0273, -0.0048],\n",
            "        [ 0.0461, -0.0439, -0.0409, -0.0466, -0.0419,  0.0225, -0.0403, -0.0404,\n",
            "         -0.0218,  0.0218]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Predicted probabilities\n",
            "tensor([[0.1084, 0.0961, 0.0947, 0.0997, 0.1013, 0.1005, 0.0997, 0.0960, 0.0994,\n",
            "         0.1041],\n",
            "        [0.1087, 0.0976, 0.0986, 0.0997, 0.0966, 0.1005, 0.1016, 0.0967, 0.0988,\n",
            "         0.1011],\n",
            "        [0.1066, 0.0974, 0.0977, 0.0972, 0.0976, 0.1041, 0.0978, 0.0978, 0.0996,\n",
            "         0.1041]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probabilities = softmax(logits)\n",
        "print(f\"Logits\\n{logits}\\n\")\n",
        "print(f\"Predicted probabilities\\n{pred_probabilities}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNvcI0Du3U6F"
      },
      "source": [
        "## Mini Challenge\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/ntu-dl-bootcamp/deep-learning-2025/raw/main/SESSION2/mini-challenge-session-2.png\" width=\"600\">\n",
        "</p>\n",
        "\n",
        "**Your Task:**\n",
        "\n",
        "1. Implement the neural network architecture shown in the image (using `nn.Module` in PyTorch).\n",
        "2. Train the network using reasonable hyperparameters (e.g., learning rate, batch size, number of epochs).\n",
        "3. Compare its performance (accuracy/loss) with the previous model you built."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQkd3ymes7de"
      },
      "source": [
        "## Model parameters\n",
        "\n",
        "Many layers inside a neural network are parameterised. This means that they have associated weights and biases that are optimised during training.\n",
        "\n",
        "`nn.Module` tracks all the parameters inside a model object. This can be accessed using the model's `parameters()` and `named_parameters()` methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3O_i67KtgiB",
        "outputId": "728ee7c5-5c71-461a-bf8a-83d6658bc794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This loop helps us inspect the parameters (weights and biases) of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_hbJ8tlsgaT",
        "outputId": "646e23d4-1a97-4c51-8d2e-9f4bcc66f868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0179,  0.0310,  0.0006,  ...,  0.0313, -0.0108, -0.0252],\n",
            "        [-0.0155, -0.0299, -0.0289,  ..., -0.0213,  0.0279,  0.0122]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0330, 0.0078], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0289, -0.0371, -0.0174,  ..., -0.0232, -0.0356, -0.0024],\n",
            "        [ 0.0079,  0.0224, -0.0101,  ..., -0.0250, -0.0436, -0.0169]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0366, -0.0388], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0073,  0.0410, -0.0408,  ...,  0.0350, -0.0339,  0.0099],\n",
            "        [ 0.0299,  0.0275, -0.0321,  ...,  0.0417, -0.0422, -0.0396]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0290, -0.0047], grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIxBFWs0uAER"
      },
      "source": [
        "# Optimizing the Model's Parameters\n",
        "\n",
        "Once we have a model and data, the next step is to **train** the model by adjusting its parameters so that its predictions improve.\n",
        "\n",
        "Training is an **iterative** process. In each iteration:\n",
        "\n",
        "1. The model **makes a prediction**.\n",
        "2. We **measure the error** using a **loss function**.\n",
        "3. We compute how the error **changes with respect to each parameter** (this is done automatically by PyTorch using **backpropagation**).\n",
        "4. We **update the parameters** to reduce the error (using **gradient descent** or a variant of it).\n",
        "\n",
        "## Hyperparameters\n",
        "\n",
        "**Hyperparameters** are settings that control how the training process behaves.  \n",
        "They are **not** learned by the model â€” we choose them manually.\n",
        "\n",
        "Key hyperparameters we will use:\n",
        "\n",
        "1. **Number of epochs**  \n",
        "   How many times we go through the entire training dataset.\n",
        "\n",
        "2. **Batch size**  \n",
        "   How many samples the model sees **before** the parameters are updated.\n",
        "\n",
        "3. **Learning rate**  \n",
        "   How big the parameter update step is during optimization. \n",
        "\n",
        "Choosing good hyperparameters is important for effective learning and stable convergence.\n",
        "\n",
        "<div style=\"border: 2px solid #4A90E2; padding: 10px; border-radius: 6px;\">\n",
        "<strong> ðŸš© Question:</strong>  \n",
        "How might changing the learning rate affect the training process?\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rgzqm7J0teHU"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16v62WF2vvUB"
      },
      "source": [
        "## Optimisation loop\n",
        "Using these hyperparamters, we can train and optimise the paramters of our model with an optimisation loop. Each iteration of the optimisation loop is called as an **epoch**.\n",
        "\n",
        "Each epoch has two parts\n",
        "1. Iterate over the training loop and update the parameters\n",
        "2. Iterate over the test / validation loop and check if the model's performance is improving.\n",
        "\n",
        "Two important concepts used in the training loop are the loss function and the optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp1EmysNw0_V"
      },
      "source": [
        "# Loss Function\n",
        "\n",
        "When our network is first initialized, its predictions will usually be incorrect.  \n",
        "A **loss function** tells us *how far off* the modelâ€™s predictions are from the true labels.  \n",
        "During training, we aim to **minimize this loss**.\n",
        "\n",
        "To compute the loss:\n",
        "1. The model makes a **prediction** from the input.\n",
        "2. The prediction is **compared with the true label**.\n",
        "3. The loss function outputs a **single number** representing the error.\n",
        "\n",
        "### Common Loss Functions\n",
        "\n",
        "| Loss Function | Use Case | Notes |\n",
        "|--------------|----------|-------|\n",
        "| **`nn.MSELoss`** | Regression tasks | Measures squared difference between prediction and target. |\n",
        "| **`nn.NLLLoss`** | Classification | Works with log-probabilities. |\n",
        "| **`nn.CrossEntropyLoss`** | Classification | Combines `LogSoftmax` + `NLLLoss`. Works directly on raw logits. |\n",
        "\n",
        "We will use **`nn.CrossEntropyLoss`**, which:\n",
        "- Takes the modelâ€™s raw outputs (**logits**),\n",
        "- Applies the appropriate normalization internally,\n",
        "- Computes how wrong the prediction is.\n",
        "\n",
        "This makes it well-suited for multi-class classification problems like MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "uCwdivyPvtU-"
      },
      "outputs": [],
      "source": [
        "# initialise the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUTADFRRyDPh"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "**Optimization** is the process of adjusting the modelâ€™s parameters so that the loss decreases over time.\n",
        "\n",
        "An **optimizer** defines *how* these parameter updates are performed.\n",
        "\n",
        "In our example, we use **Stochastic Gradient Descent (SGD)**, but PyTorch provides many others such as **Adam** and **RMSProp**, which may work better depending on the task.\n",
        "\n",
        "To create an optimizer, we:\n",
        "1. **Pass in the modelâ€™s parameters** (so the optimizer knows what to update)\n",
        "2. Set the **learning rate** (to control how big each update step is)\n",
        "\n",
        "Once defined, the optimizer will handle the parameter updates during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PVZHgyi1x96X"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eP1Jmy_ygVu"
      },
      "source": [
        "Inside the training loop, the optimizer updates the model parameters in **three steps**:\n",
        "\n",
        "1. **Reset the gradients**\n",
        "\n",
        "Gradients accumulate by default in PyTorch. We reset them each iteration to avoid carrying over values from the previous updat\n",
        "\n",
        "```python\n",
        "optimizer.zero_grad()\n",
        "```\n",
        "\n",
        "2. **Backpropagate the loss**\n",
        "\n",
        "This computes how the loss changes with respect to each model parameter and stores the gradients.\n",
        "\n",
        "```python\n",
        "loss.backward()\n",
        "```\n",
        "\n",
        "3. **Update the parameters**\n",
        "\n",
        "The optimizer adjusts the parameters using the computed gradients (e.g., gradient descent).\n",
        "\n",
        "```python\n",
        "optimizer.step()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va8teUI_yv3P"
      },
      "source": [
        "## Full training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "k0vXWA8nyZ0D"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute the prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2GpV7NVzYGd"
      },
      "source": [
        "## Full testing loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qB4TaHEKzVvu"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode - important for batch normalisation and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(\n",
        "        f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2w54rd80AXO"
      },
      "source": [
        "We initialize the loss function and optimizer, and pass it to train_loop and test_loop. Feel free to increase the number of epochs to track the modelâ€™s improving performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xJvDE0Ez69a",
        "outputId": "2cc58c97-0e6a-4977-e3cb-b8706fe06a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.300085  [   64/60000]\n",
            "loss: 2.292223  [ 6464/60000]\n",
            "loss: 2.294612  [12864/60000]\n",
            "loss: 2.283162  [19264/60000]\n",
            "loss: 2.279641  [25664/60000]\n",
            "loss: 2.282388  [32064/60000]\n",
            "loss: 2.272002  [38464/60000]\n",
            "loss: 2.273226  [44864/60000]\n",
            "loss: 2.253159  [51264/60000]\n",
            "loss: 2.254613  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 42.3%, Avg loss: 2.251972 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.245827  [   64/60000]\n",
            "loss: 2.235991  [ 6464/60000]\n",
            "loss: 2.247810  [12864/60000]\n",
            "loss: 2.227066  [19264/60000]\n",
            "loss: 2.221572  [25664/60000]\n",
            "loss: 2.218985  [32064/60000]\n",
            "loss: 2.211084  [38464/60000]\n",
            "loss: 2.212244  [44864/60000]\n",
            "loss: 2.221478  [51264/60000]\n",
            "loss: 2.179286  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 56.8%, Avg loss: 2.185574 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.170178  [   64/60000]\n",
            "loss: 2.178241  [ 6464/60000]\n",
            "loss: 2.150765  [12864/60000]\n",
            "loss: 2.124737  [19264/60000]\n",
            "loss: 2.152570  [25664/60000]\n",
            "loss: 2.144791  [32064/60000]\n",
            "loss: 2.120190  [38464/60000]\n",
            "loss: 2.105145  [44864/60000]\n",
            "loss: 2.076928  [51264/60000]\n",
            "loss: 2.076045  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.0%, Avg loss: 2.069895 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.064329  [   64/60000]\n",
            "loss: 2.057597  [ 6464/60000]\n",
            "loss: 2.038524  [12864/60000]\n",
            "loss: 1.974392  [19264/60000]\n",
            "loss: 2.020957  [25664/60000]\n",
            "loss: 1.987805  [32064/60000]\n",
            "loss: 1.882518  [38464/60000]\n",
            "loss: 1.968383  [44864/60000]\n",
            "loss: 1.877202  [51264/60000]\n",
            "loss: 1.885270  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 69.3%, Avg loss: 1.872174 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.820463  [   64/60000]\n",
            "loss: 1.846708  [ 6464/60000]\n",
            "loss: 1.837087  [12864/60000]\n",
            "loss: 1.757153  [19264/60000]\n",
            "loss: 1.713511  [25664/60000]\n",
            "loss: 1.662237  [32064/60000]\n",
            "loss: 1.732018  [38464/60000]\n",
            "loss: 1.663088  [44864/60000]\n",
            "loss: 1.622883  [51264/60000]\n",
            "loss: 1.549651  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 74.3%, Avg loss: 1.579702 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.481672  [   64/60000]\n",
            "loss: 1.621238  [ 6464/60000]\n",
            "loss: 1.566664  [12864/60000]\n",
            "loss: 1.403534  [19264/60000]\n",
            "loss: 1.475005  [25664/60000]\n",
            "loss: 1.438483  [32064/60000]\n",
            "loss: 1.452724  [38464/60000]\n",
            "loss: 1.299031  [44864/60000]\n",
            "loss: 1.393918  [51264/60000]\n",
            "loss: 1.243907  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 78.0%, Avg loss: 1.258843 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.225866  [   64/60000]\n",
            "loss: 1.244359  [ 6464/60000]\n",
            "loss: 1.296411  [12864/60000]\n",
            "loss: 1.201280  [19264/60000]\n",
            "loss: 1.221399  [25664/60000]\n",
            "loss: 1.128611  [32064/60000]\n",
            "loss: 1.055395  [38464/60000]\n",
            "loss: 0.969901  [44864/60000]\n",
            "loss: 0.938652  [51264/60000]\n",
            "loss: 0.955977  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.2%, Avg loss: 1.001407 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.055537  [   64/60000]\n",
            "loss: 0.964503  [ 6464/60000]\n",
            "loss: 0.974892  [12864/60000]\n",
            "loss: 0.847950  [19264/60000]\n",
            "loss: 0.947378  [25664/60000]\n",
            "loss: 1.056584  [32064/60000]\n",
            "loss: 0.746905  [38464/60000]\n",
            "loss: 0.950663  [44864/60000]\n",
            "loss: 0.907195  [51264/60000]\n",
            "loss: 0.803613  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.0%, Avg loss: 0.828166 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.955183  [   64/60000]\n",
            "loss: 0.607666  [ 6464/60000]\n",
            "loss: 0.780492  [12864/60000]\n",
            "loss: 0.751392  [19264/60000]\n",
            "loss: 0.785876  [25664/60000]\n",
            "loss: 0.871002  [32064/60000]\n",
            "loss: 0.695686  [38464/60000]\n",
            "loss: 0.846741  [44864/60000]\n",
            "loss: 0.687934  [51264/60000]\n",
            "loss: 0.774802  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.2%, Avg loss: 0.713437 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.733391  [   64/60000]\n",
            "loss: 0.817433  [ 6464/60000]\n",
            "loss: 0.717490  [12864/60000]\n",
            "loss: 0.649851  [19264/60000]\n",
            "loss: 0.942781  [25664/60000]\n",
            "loss: 0.616911  [32064/60000]\n",
            "loss: 0.654127  [38464/60000]\n",
            "loss: 0.687844  [44864/60000]\n",
            "loss: 0.584430  [51264/60000]\n",
            "loss: 0.564867  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.634853 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "YaiHC_ee0Mxw",
        "outputId": "56d0e4f9-9507-4c57-9e9a-3c20176329b0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 4\n",
            "\n",
            "Predicted class: tensor([4])\n"
          ]
        }
      ],
      "source": [
        "img, label = training_data[20]\n",
        "\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\\n\")\n",
        "\n",
        "img = img.to(device)\n",
        "logits = model(img)\n",
        "predicted_probabilities = nn.Softmax(dim=1)(logits)\n",
        "predicted_class = torch.argmax(predicted_probabilities, dim=1)\n",
        "print(f\"Predicted class: {predicted_class}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-0zo4un1oGq"
      },
      "source": [
        "# Save and load the model\n",
        "\n",
        "PyTorch models store the learned parameters in an internal state dictionary, called state_dict. **These can be saved using the torch.save method.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEisYOlX1ewU"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model_weights.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPMoBfgc18Nd"
      },
      "source": [
        "To load model weights, you need to create an instance of the same model first, and then load the parameters using `load_state_dict()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsM4JHMy13oH",
        "outputId": "4c8a287c-bed1-4dd2-88cd-8de095157719"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-110-3e20348b5a1b>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_new.load_state_dict(torch.load('model_weights.pth'))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_new = NeuralNetwork().to(device)\n",
        "\n",
        "model_new.load_state_dict(torch.load(\"model_weights.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "kARmbf6s2LWJ",
        "outputId": "09a37dc3-7a40-436d-e95d-50c02d3c2040"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 4\n",
            "\n",
            "Predicted class: tensor([4])\n"
          ]
        }
      ],
      "source": [
        "# Testing the newly loaded model, `model_new`\n",
        "\n",
        "img, label = training_data[20]\n",
        "\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\\n\")\n",
        "\n",
        "img = img.to(device)\n",
        "logits = model_new(img)\n",
        "predicted_probabilities = nn.Softmax(dim=1)(logits)\n",
        "predicted_class = torch.argmax(predicted_probabilities, dim=1)\n",
        "print(f\"Predicted class: {predicted_class}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCKMg_VuDY1M"
      },
      "source": [
        "# Recommended Reading and Other Resources\n",
        "1. [What is torch.nn really?](https://pytorch.org/tutorials/beginner/nn_tutorial.html)\n",
        "2. [PyTorch Beginner Series](https://www.youtube.com/playlist?list=PL_lsbAsL_o2CTlGHgMxNrKhzP97BaG9ZN)\n",
        "\n",
        "This notebook is based on [Learn the Basics](https://pytorch.org/tutorials/beginner/basics/intro.html)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "subcortical-seg-cnn-atlas",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
