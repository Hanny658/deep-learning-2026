{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ntu-dl-bootcamp/deep-learning-2026/blob/main/SESSION2/session2_part2.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Datasets and DataLoaders in PyTorch\n",
        "\n",
        "| Component      | Purpose                                                                 | Think of it as...                                   |\n",
        "|----------------|-------------------------------------------------------------------------|-----------------------------------------------------|\n",
        "| **Dataset**     | Stores the data and labels, and knows how to return **one sample**      | A **bookshelf** full of data                        |\n",
        "| **DataLoader**  | Efficiently provides the data to the model in **mini-batches**, optionally **shuffled** | A **librarian** handing small stacks of books to you |\n",
        "\n",
        "When training a deep learning model, we typically work with many samples (e.g., thousands of images). We do **not** feed all samples to the model at once. Instead, we train using **mini-batches** (small groups of samples per step).\n",
        "\n",
        "PyTorch provides many ready-to-use datasets:\n",
        "\n",
        "- **Image:** https://pytorch.org/vision/stable/datasets.html  \n",
        "- **Text:** https://pytorch.org/text/stable/datasets.html  \n",
        "- **Audio:** https://pytorch.org/audio/stable/datasets.html\n",
        "\n",
        "> ðŸš© Question:</strong> Why don't we feed all the samples to the model at once?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWxqggWBX1cB"
      },
      "source": [
        "## Loading a Dataset\n",
        "\n",
        "The **MNIST** (Modified National Institute of Standards and Technology) dataset is a classic benchmark dataset of handwritten digits used widely in machine learning and deep learning.\n",
        "\n",
        "Each image in the dataset is:\n",
        "\n",
        "- **28 Ã— 28** pixels (grayscale)\n",
        "- **Labeled** with a digit **0â€“9**\n",
        "- Part of a collection of **70,000 images**  \n",
        "  - **60,000** for training  \n",
        "  - **10,000** for testing  \n",
        "\n",
        "Because the images are small and simple, MNIST is ideal for learning the basics of building and training neural networks.\n",
        "\n",
        "We will load MNIST using `torchvision.datasets`.\n",
        "\n",
        "More details here: https://en.wikipedia.org/wiki/MNIST_database\n",
        "\n",
        "\n",
        "> What does a PyTorch Dataset contain?\n",
        "> \n",
        "> - The **input samples** (in this case, images of digits)\n",
        "> - The corresponding **labels** (which digit each image represents)\n",
        "> - A method to retrieve a **single** example at a time:  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wvWcdvSOVxjU"
      },
      "outputs": [],
      "source": [
        "# Import the necessary modules from torchvision\n",
        "from torchvision import datasets  # for accessing popular datasets\n",
        "from torchvision.transforms import ToTensor  # for converting images to PyTorch tensors\n",
        "\n",
        "# Download and prepare the training data\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",  # 'root' is the directory where the dataset will be stored\n",
        "    train=True,  # 'train=True' specifies that we want the training set\n",
        "    download=True,  # 'download=True' will download the dataset if it's not already present\n",
        "    transform=ToTensor(),  # 'transform=ToTensor()' converts the images to PyTorch tensors (needed for PyTorch models)\n",
        ")\n",
        "\n",
        "# Download and prepare the test data\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",  # Store the test data in the same directory as training data\n",
        "    train=False,  # 'train=False' specifies that we want the test set\n",
        "    download=True,  # 'download=True' will download the test dataset if it's not already present\n",
        "    transform=ToTensor(),  # Convert test images to tensors, just like the training data\n",
        ")\n",
        "\n",
        "# Explanation:\n",
        "# - datasets.MNIST() provides access to the MNIST dataset, with options to load either training or test data.\n",
        "# - ToTensor() transforms each image from a PIL image format (used by default) to a PyTorch tensor.\n",
        "# - The 'root' parameter specifies where the data should be saved on your system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84rMBLuMZfJD",
        "outputId": "9ea3911a-776e-43cf-baa1-f95cbe167b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in training data  60000\n",
            "Number of samples in test data  10000\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of samples in training data \", len(training_data))\n",
        "print(\"Number of samples in test data \", len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63vl9X_hbHP0",
        "outputId": "4abd0c7c-8306-40f3-ba80-ec388c082079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image shape before np.squeeze: torch.Size([1, 28, 28])\n",
            "Image shape before np.squeeze: torch.Size([28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Import the necessary module for plotting images\n",
        "import matplotlib.pyplot as plt  # 'matplotlib.pyplot' is a library for creating visualizations in Python\n",
        "\n",
        "# Access the 10th image and its label from the training dataset\n",
        "image, label = training_data[\n",
        "    10\n",
        "]  # 'training_data[10]' retrieves the 9th image and its label from the dataset\n",
        "\n",
        "# Print the shape of the image tensor\n",
        "print(\n",
        "    f\"Image shape before np.squeeze: {image.shape}\"\n",
        ")  # dimensions of the image tensor before any modifications\n",
        "\n",
        "# Remove the single color channel dimension from the image tensor\n",
        "image = (\n",
        "    image.squeeze()\n",
        ")  # 'squeeze()' removes extra dimensions of size 1 (from [1, 28, 28] to [28, 28])\n",
        "\n",
        "# Print the shape of the image tensor after squeezing\n",
        "print(f\"Image shape before np.squeeze: {image.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "q88dR3tfGBPV",
        "outputId": "d31c5021-4995-492f-aa5e-4cf766752ef7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZ7ElEQVR4nO3df0zU9x3H8dfVH+cvuIYq3DGREKdpVwxb1amk/twkktTU2ibWLgv+4+z8kVg0Zs5ssqWRzkxjGqbLmoZpVjv/qDoTTSuLgi7OhRpMnbUGJxY6JURq7xAtTP3sD+PFKxT9nne+OXg+km9S7r4fv2+//erTLweHzznnBACAgSesBwAA9F9ECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmBloPcA33blzR5cvX1ZaWpp8Pp/1OAAAj5xzamtrU3Z2tp54oud7nV4XocuXLysnJ8d6DADAI2pqatLo0aN73KfXfTouLS3NegQAQAI8zN/nSYvQ9u3blZeXpyFDhmjixIk6fvz4Q63jU3AA0Dc8zN/nSYnQnj17tHr1am3YsEF1dXWaPn26iouL1djYmIzDAQBSlC8Z76I9ZcoUPffcc9qxY0f0sWeeeUYLFixQeXl5j2sjkYgCgUCiRwIAPGbhcFjp6ek97pPwO6HOzk6dOnVKRUVFMY8XFRXpxIkTXfbv6OhQJBKJ2QAA/UPCI3T16lXdvn1bWVlZMY9nZWWpubm5y/7l5eUKBALRja+MA4D+I2lfmPDNF6Scc92+SLV+/XqFw+Ho1tTUlKyRAAC9TMK/T2jkyJEaMGBAl7uelpaWLndHkuT3++X3+xM9BgAgBST8Tmjw4MGaOHGiqqqqYh6vqqpSYWFhog8HAEhhSXnHhNLSUv30pz/VpEmTNG3aNP3pT39SY2OjXn/99WQcDgCQopISoUWLFqm1tVW//e1vdeXKFeXn5+vQoUPKzc1NxuEAACkqKd8n9Cj4PiEA6BtMvk8IAICHRYQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwMtB4ASIbvfe97ca174YUXPK/52c9+5nlNbW2t5zV1dXWe18Rr27Ztntd0dnYmfhD0edwJAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmfM45Zz3E/SKRiAKBgPUY6EWWLVvmec3vf//7uI41YsSIuNb1NXPmzPG85ujRo0mYBKksHA4rPT29x324EwIAmCFCAAAzCY9QWVmZfD5fzBYMBhN9GABAH5CUH2r37LPP6u9//3v04wEDBiTjMACAFJeUCA0cOJC7HwDAAyXlNaH6+nplZ2crLy9Pr776qi5evPit+3Z0dCgSicRsAID+IeERmjJlinbt2qWPPvpI77zzjpqbm1VYWKjW1tZu9y8vL1cgEIhuOTk5iR4JANBLJTxCxcXFevnllzVhwgT9+Mc/1sGDByVJO3fu7Hb/9evXKxwOR7empqZEjwQA6KWS8prQ/YYPH64JEyaovr6+2+f9fr/8fn+yxwAA9EJJ/z6hjo4OnTt3TqFQKNmHAgCkmIRHaO3ataqpqVFDQ4P+9a9/6ZVXXlEkElFJSUmiDwUASHEJ/3TcF198ocWLF+vq1asaNWqUpk6dqpMnTyo3NzfRhwIApDjewBS9XkZGhuc1586di+tYmZmZca3ra7766ivPaxYtWuR5zeHDhz2vQergDUwBAL0aEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGAm6T/UDnhUX375pec1GzdujOtYW7Zs8bxm2LBhntc0NjZ6XjNmzBjPa+L15JNPel4zb948z2t4A1NwJwQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzPuecsx7ifpFIRIFAwHoM9FOnT5/2vKagoMDzmn//+9+e1+Tn53te8ziNHTvW85qLFy8mYRL0FuFwWOnp6T3uw50QAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGBmoPUAQG/y5ptvel6zYcMGz2u+//3ve17T2w0ePNh6BKQg7oQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADM+55yzHuJ+kUhEgUDAegzgoQWDQc9rDh8+7HnNhAkTPK95nD744APPa1555ZUkTILeIhwOKz09vcd9uBMCAJghQgAAM54jdOzYMc2fP1/Z2dny+Xzav39/zPPOOZWVlSk7O1tDhw7VrFmzdPbs2UTNCwDoQzxHqL29XQUFBaqoqOj2+c2bN2vr1q2qqKhQbW2tgsGg5s6dq7a2tkceFgDQt3j+yarFxcUqLi7u9jnnnLZt26YNGzZo4cKFkqSdO3cqKytLu3fv1rJlyx5tWgBAn5LQ14QaGhrU3NysoqKi6GN+v18zZ87UiRMnul3T0dGhSCQSswEA+oeERqi5uVmSlJWVFfN4VlZW9LlvKi8vVyAQiG45OTmJHAkA0Isl5avjfD5fzMfOuS6P3bN+/XqFw+Ho1tTUlIyRAAC9kOfXhHpy75v2mpubFQqFoo+3tLR0uTu6x+/3y+/3J3IMAECKSOidUF5enoLBoKqqqqKPdXZ2qqamRoWFhYk8FACgD/B8J3T9+nVduHAh+nFDQ4NOnz6tjIwMjRkzRqtXr9amTZs0btw4jRs3Tps2bdKwYcP02muvJXRwAEDq8xyhjz/+WLNnz45+XFpaKkkqKSnRn//8Z61bt043b97U8uXLde3aNU2ZMkWHDx9WWlpa4qYGAPQJvIEpcJ+f/OQnntcUFBR4XrN27VrPa77ti3t6izfeeMPzmm3btiV+EPQavIEpAKBXI0IAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgJmE/mRVIBmefvppz2v27dsX17G++93vel4zcCB/jCTpwIED1iMgBXEnBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4Z0X0es988wzntfk5eXFdSzejDR+b7zxhuc1q1atSsIkSCXcCQEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZni3RvR6+/bt87xm3bp1cR3rd7/7nec1Q4YMietYfU0oFLIeASmIOyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAxvYIo+6e23345rXX19vec1Tz75ZFzH8mrgQO9/XCsqKuI6Vnp6elzrAK+4EwIAmCFCAAAzniN07NgxzZ8/X9nZ2fL5fNq/f3/M80uWLJHP54vZpk6dmqh5AQB9iOcItbe3q6CgoMfPNc+bN09XrlyJbocOHXqkIQEAfZPnVzqLi4tVXFzc4z5+v1/BYDDuoQAA/UNSXhOqrq5WZmamxo8fr6VLl6qlpeVb9+3o6FAkEonZAAD9Q8IjVFxcrPfee09HjhzRli1bVFtbqzlz5qijo6Pb/cvLyxUIBKJbTk5OokcCAPRSCf8+oUWLFkX/Oz8/X5MmTVJubq4OHjyohQsXdtl//fr1Ki0tjX4ciUQIEQD0E0n/ZtVQKKTc3Nxv/SZAv98vv9+f7DEAAL1Q0r9PqLW1VU1NTQqFQsk+FAAgxXi+E7p+/bouXLgQ/bihoUGnT59WRkaGMjIyVFZWppdfflmhUEiXLl3SL3/5S40cOVIvvfRSQgcHAKQ+zxH6+OOPNXv27OjH917PKSkp0Y4dO3TmzBnt2rVLX331lUKhkGbPnq09e/YoLS0tcVMDAPoEn3POWQ9xv0gkokAgYD0G0Ov4fD7Pa8rKyuI61q9//WvPa/7zn/94XvOjH/3I85rPP//c8xrYCIfDD3wzXN47DgBghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaS/pNVASTG4MGDPa+J592w4/W///3P85rbt28nYRKkEu6EAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzvIEpkCLefPNN6xF69O6773pe88UXXyRhEqQS7oQAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADM+55yzHuJ+kUhEgUDAeoyU9dRTT3leU1lZGdex3n///ceypi8KhUKe13z22Wee16Snp3teE6+xY8d6XnPx4sUkTILeIhwOP/Aa5E4IAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADAz0HoAJNbbb7/tec38+fPjOtb48eM9r7l8+bLnNf/97389r7lw4YLnNZI0ceJEz2viOQ/r1q3zvOZxvhnpli1bPK+J5/8twJ0QAMAMEQIAmPEUofLyck2ePFlpaWnKzMzUggULdP78+Zh9nHMqKytTdna2hg4dqlmzZuns2bMJHRoA0Dd4ilBNTY1WrFihkydPqqqqSrdu3VJRUZHa29uj+2zevFlbt25VRUWFamtrFQwGNXfuXLW1tSV8eABAavP0hQkffvhhzMeVlZXKzMzUqVOnNGPGDDnntG3bNm3YsEELFy6UJO3cuVNZWVnavXu3li1blrjJAQAp75FeEwqHw5KkjIwMSVJDQ4Oam5tVVFQU3cfv92vmzJk6ceJEt79GR0eHIpFIzAYA6B/ijpBzTqWlpXr++eeVn58vSWpubpYkZWVlxeyblZUVfe6bysvLFQgEoltOTk68IwEAUkzcEVq5cqU++eQTvf/++12e8/l8MR8757o8ds/69esVDoejW1NTU7wjAQBSTFzfrLpq1SodOHBAx44d0+jRo6OPB4NBSXfviEKhUPTxlpaWLndH9/j9fvn9/njGAACkOE93Qs45rVy5Unv37tWRI0eUl5cX83xeXp6CwaCqqqqij3V2dqqmpkaFhYWJmRgA0Gd4uhNasWKFdu/erb/97W9KS0uLvs4TCAQ0dOhQ+Xw+rV69Wps2bdK4ceM0btw4bdq0ScOGDdNrr72WlN8AACB1eYrQjh07JEmzZs2KebyyslJLliyRdPc9sW7evKnly5fr2rVrmjJlig4fPqy0tLSEDAwA6Dt8zjlnPcT9IpGIAoGA9Rgpa+rUqZ7XbN26Na5jTZs2La51Xl26dMnzmk8//TSuY02fPt3zmsf1D6x4/qh+9tlncR1r8uTJntfc/03rgHT323ge9Ma7vHccAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzPAu2tCWLVviWnfhwgXPa7Zv3x7XsSB9+eWXntc89dRTSZgEeDi8izYAoFcjQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwMtB4A9tasWRPXOr/f73nNiBEj4jqWVz/4wQ/iWrd48eIET9K9cDjsec3cuXOTMAlgizshAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMCMzznnrIe4XyQSUSAQsB4DAPCIwuGw0tPTe9yHOyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABgxlOEysvLNXnyZKWlpSkzM1MLFizQ+fPnY/ZZsmSJfD5fzDZ16tSEDg0A6Bs8RaimpkYrVqzQyZMnVVVVpVu3bqmoqEjt7e0x+82bN09XrlyJbocOHUro0ACAvmGgl50//PDDmI8rKyuVmZmpU6dOacaMGdHH/X6/gsFgYiYEAPRZj/SaUDgcliRlZGTEPF5dXa3MzEyNHz9eS5cuVUtLy7f+Gh0dHYpEIjEbAKB/8DnnXDwLnXN68cUXde3aNR0/fjz6+J49ezRixAjl5uaqoaFBv/rVr3Tr1i2dOnVKfr+/y69TVlam3/zmN/H/DgAAvVI4HFZ6enrPO7k4LV++3OXm5rqmpqYe97t8+bIbNGiQ++CDD7p9/uuvv3bhcDi6NTU1OUlsbGxsbCm+hcPhB7bE02tC96xatUoHDhzQsWPHNHr06B73DYVCys3NVX19fbfP+/3+bu+QAAB9n6cIOee0atUq7du3T9XV1crLy3vgmtbWVjU1NSkUCsU9JACgb/L0hQkrVqzQX/7yF+3evVtpaWlqbm5Wc3Ozbt68KUm6fv261q5dq3/+85+6dOmSqqurNX/+fI0cOVIvvfRSUn4DAIAU5uV1IH3L5/0qKyudc87duHHDFRUVuVGjRrlBgwa5MWPGuJKSEtfY2PjQxwiHw+afx2RjY2Nje/TtYV4Tivur45IlEokoEAhYjwEAeEQP89VxvHccAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMBMr4uQc856BABAAjzM3+e9LkJtbW3WIwAAEuBh/j73uV5263Hnzh1dvnxZaWlp8vl8Mc9FIhHl5OSoqalJ6enpRhPa4zzcxXm4i/NwF+fhrt5wHpxzamtrU3Z2tp54oud7nYGPaaaH9sQTT2j06NE97pOent6vL7J7OA93cR7u4jzcxXm4y/o8BAKBh9qv1306DgDQfxAhAICZlIqQ3+/Xxo0b5ff7rUcxxXm4i/NwF+fhLs7DXal2HnrdFyYAAPqPlLoTAgD0LUQIAGCGCAEAzBAhAICZlIrQ9u3blZeXpyFDhmjixIk6fvy49UiPVVlZmXw+X8wWDAatx0q6Y8eOaf78+crOzpbP59P+/ftjnnfOqaysTNnZ2Ro6dKhmzZqls2fP2gybRA86D0uWLOlyfUydOtVm2CQpLy/X5MmTlZaWpszMTC1YsEDnz5+P2ac/XA8Pcx5S5XpImQjt2bNHq1ev1oYNG1RXV6fp06eruLhYjY2N1qM9Vs8++6yuXLkS3c6cOWM9UtK1t7eroKBAFRUV3T6/efNmbd26VRUVFaqtrVUwGNTcuXP73PsQPug8SNK8efNiro9Dhw49xgmTr6amRitWrNDJkydVVVWlW7duqaioSO3t7dF9+sP18DDnQUqR68GliB/+8Ifu9ddfj3ns6aefdr/4xS+MJnr8Nm7c6AoKCqzHMCXJ7du3L/rxnTt3XDAYdG+99Vb0sa+//toFAgH3xz/+0WDCx+Ob58E550pKStyLL75oMo+VlpYWJ8nV1NQ45/rv9fDN8+Bc6lwPKXEn1NnZqVOnTqmoqCjm8aKiIp04ccJoKhv19fXKzs5WXl6eXn31VV28eNF6JFMNDQ1qbm6OuTb8fr9mzpzZ764NSaqurlZmZqbGjx+vpUuXqqWlxXqkpAqHw5KkjIwMSf33evjmebgnFa6HlIjQ1atXdfv2bWVlZcU8npWVpebmZqOpHr8pU6Zo165d+uijj/TOO++oublZhYWFam1ttR7NzL3///392pCk4uJivffeezpy5Ii2bNmi2tpazZkzRx0dHdajJYVzTqWlpXr++eeVn58vqX9eD92dByl1rode9y7aPfnmj3ZwznV5rC8rLi6O/veECRM0bdo0jR07Vjt37lRpaanhZPb6+7UhSYsWLYr+d35+viZNmqTc3FwdPHhQCxcuNJwsOVauXKlPPvlE//jHP7o815+uh287D6lyPaTEndDIkSM1YMCALv+SaWlp6fIvnv5k+PDhmjBhgurr661HMXPvqwO5NroKhULKzc3tk9fHqlWrdODAAR09ejTmR7/0t+vh285Dd3rr9ZASERo8eLAmTpyoqqqqmMerqqpUWFhoNJW9jo4OnTt3TqFQyHoUM3l5eQoGgzHXRmdnp2pqavr1tSFJra2tampq6lPXh3NOK1eu1N69e3XkyBHl5eXFPN9frocHnYfu9NrrwfCLIjz561//6gYNGuTeffdd9+mnn7rVq1e74cOHu0uXLlmP9tisWbPGVVdXu4sXL7qTJ0+6F154waWlpfX5c9DW1ubq6upcXV2dk+S2bt3q6urq3Oeff+6cc+6tt95ygUDA7d271505c8YtXrzYhUIhF4lEjCdPrJ7OQ1tbm1uzZo07ceKEa2hocEePHnXTpk1z3/nOd/rUefj5z3/uAoGAq66udleuXIluN27ciO7TH66HB52HVLoeUiZCzjn3hz/8weXm5rrBgwe75557LubLEfuDRYsWuVAo5AYNGuSys7PdwoUL3dmzZ63HSrqjR486SV22kpIS59zdL8vduHGjCwaDzu/3uxkzZrgzZ87YDp0EPZ2HGzduuKKiIjdq1Cg3aNAgN2bMGFdSUuIaGxutx06o7n7/klxlZWV0n/5wPTzoPKTS9cCPcgAAmEmJ14QAAH0TEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGDm/znf4gnjv6/sAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 3\n"
          ]
        }
      ],
      "source": [
        "# Display the image using matplotlib\n",
        "plt.imshow(image, cmap=\"gray\")  # 'cmap='gray'' shows it in grayscale\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")\n",
        "\n",
        "# TODO: Try to visualise a different sample from the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ðŸš© TODO Try to visualise a different sample from the dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_IJ3lSGbjrb"
      },
      "source": [
        "## Preparing Your Data for Use in a Model Using DataLoaders\n",
        "\n",
        "The `Dataset` we created above gives us **one sample at a time**.  \n",
        "But when training a neural network, we usually don't feed samples one-by-one. Instead, we want to:\n",
        "\n",
        "1. **Group samples into mini-batches** (so the model sees several examples at once)\n",
        "2. **Shuffle** the samples (more on this later)\n",
        "3. **Load data efficiently**, possibly using multiple CPU cores\n",
        "\n",
        "A **DataLoader** is an _iterable_ that takes a `Dataset` and handles all of this automatically. It prepares mini-batches for us, shuffles when needed, and can speed up data loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D_VIlqzFaqT5"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D9vtcvndAwr"
      },
      "source": [
        "We have loaded our dataset into a `DataLoader`, which allows us to iterate through the data in **batches**. Each iteration returns a batch of `train_features` and `train_labels`.\n",
        "\n",
        "If `shuffle=True` was set in the `DataLoader`, then the order of the data will **be shuffled the next time we iterate over it**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxJFfJQUcruN",
        "outputId": "ad8096dd-5c8b-4ea5-cd32-ea1c71870961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ðŸš© Question\n",
        ">\n",
        "> The feature batch has shape torch.Size([64, 1, 28, 28]) and the label batch has shape torch.Size([64]).\n",
        ">\n",
        "> What does each dimension in these shapes represent in the context of the MNIST dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "p4KwSlkRdquy",
        "outputId": "23c4d738-5471-4a8d-a229-621c841c3c20"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 9\n"
          ]
        }
      ],
      "source": [
        "# Visualising one image from the selected batch\n",
        "\n",
        "img = train_features[10].squeeze()\n",
        "label = train_labels[10]\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")\n",
        "\n",
        "# TODO: Try to visualize a different sample from this batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ðŸš© TODO Try to visualise a different sample from this batch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izv4-F3He1Og"
      },
      "source": [
        "# Build the Neural Network\n",
        "\n",
        "A **neural network** is made up of layers that transform the input data step by step.  \n",
        "\n",
        "PyTorch provides these layers and building blocks inside the `torch.nn` module.\n",
        "\n",
        "In PyTorch, every neural network component is written as a **class** that inherits from `nn.Module`.  \n",
        "This includes:\n",
        "\n",
        "- Individual layers (e.g., `nn.Linear`, `nn.Conv2d`)\n",
        "- Activation functions (e.g., `nn.ReLU`)\n",
        "- Even entire neural networks\n",
        "\n",
        "A neural network is therefore just a **module made up of other modules**.  \n",
        "This **nested structure** makes it easy to build simple or very complex models by combining layers like building blocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0fNQrmFyflkz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW80AIgEftUZ",
        "outputId": "d50a2ad2-cbed-48d6-bc3a-4d373531d388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "# check if GPU is availble\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beH1p35uG2dm"
      },
      "source": [
        "> ðŸš© Note:\n",
        "> If your output shows <em>\"Using cpu device\"</em>, your notebook is currently running on the CPU.  \n",
        "> To speed up training, switch to a GPU.\n",
        "> \n",
        "> **In Google Colab:**\n",
        "> 1. Go to **Runtime** â†’ **Change runtime type**\n",
        "> 2. Set **Hardware accelerator** to **T4 GPU**\n",
        "> 3. Save and wait for Colab to restart\n",
        "> 4. Re-run all previous cells before continuing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daZ_MXbjgjGU"
      },
      "source": [
        "Next, we define our model by creating a Python class that subclasses `nn.Module`.\n",
        "\n",
        "- In the `__init__` method, we **set up the layers** (the building blocks of the network).\n",
        "- In the `forward` method, we **describe how the input data flows through those layers**.\n",
        "\n",
        "In other words:\n",
        "\n",
        "`__init__` = *what components the network has*\n",
        "\n",
        "`forward` = *how those components are used to compute the output*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hyPYsmsZgKz6"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfhz_6KthZH0",
        "outputId": "534fe1e3-074c-42e6-be4d-a5978b3d6633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create an object of the model class and move that object to the `device` we\n",
        "# defined earlier\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "6seQ939Ehjki",
        "outputId": "5dbadcc9-d772-4ae5-cf0e-4b0c547ea7cc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 5\n",
            "\n",
            "Logits: tensor([[-0.0810, -0.0591,  0.0674,  0.0350,  0.0446, -0.0002, -0.0449, -0.0005,\n",
            "          0.0271,  0.0618]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Predicted probabilities: tensor([[0.0916, 0.0937, 0.1063, 0.1029, 0.1039, 0.0994, 0.0950, 0.0993, 0.1021,\n",
            "         0.1057]], grad_fn=<SoftmaxBackward0>)\n",
            "\n",
            "Predicted class: tensor([2])\n"
          ]
        }
      ],
      "source": [
        "# Take one sample from the dataset\n",
        "img, label = training_data[0]\n",
        "\n",
        "# Visualize the image\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\\n\")\n",
        "\n",
        "# Move the image to the same device as the model (CPU or GPU)\n",
        "img = img.to(device)\n",
        "\n",
        "# Run the image through the model (forward pass)\n",
        "logits = model(img)\n",
        "print(f\"Logits: {logits}\\n\")  # Raw, unnormalized class scores\n",
        "\n",
        "# Convert logits to probabilities\n",
        "predicted_probabilities = nn.Softmax(dim=1)(logits)\n",
        "print(f\"Predicted probabilities: {predicted_probabilities}\\n\")\n",
        "\n",
        "# Pick the class with the highest probability\n",
        "predicted_class = torch.argmax(predicted_probabilities, dim=1)\n",
        "print(f\"Predicted class: {predicted_class}\")\n",
        "\n",
        "# TODO: Try with another image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ4fwHiCm8A3"
      },
      "source": [
        "## What happens to the input at each layer in the network?\n",
        "\n",
        "To understand how data flows through our model, let's take a small **mini-batch** of 3 random images (each 28 Ã— 28) and pass them through the network layer by layer.\n",
        "\n",
        "This will help us see **how the shape of the data changes** at each step.\n",
        "\n",
        "Our model architecture:\n",
        "```\n",
        "NeuralNetwork(\n",
        "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
        "  (linear_relu_stack): Sequential(\n",
        "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
        "    (1): ReLU()\n",
        "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
        "    (3): ReLU()\n",
        "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
        "  )\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RJQy7-njEE6",
        "outputId": "8f60aac4-7092-4f85-8f4e-9c5025762024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Create a minibatch containing 3 random images of size 28 x 28\n",
        "input_minibatch = torch.rand(3, 28, 28)\n",
        "print(input_minibatch.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoVcmxHOoK61"
      },
      "source": [
        "### nn.Flatten\n",
        "\n",
        "The `nn.Flatten` layer reshapes each image from a 2D grid into a 1D vector so that it can be passed into a fully-connected (linear) layer.\n",
        "\n",
        "In our case, each MNIST image has shape 1 Ã— 28 Ã— 28 (channel, height, width).\n",
        "\n",
        "`nn.Flatten` transforms this into a 784-dimensional vector (since 28 Ã— 28 = 784), while keeping the batch size unchanged."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXTPUy1cn-O0",
        "outputId": "0ec787bd-7508-4ec1-8094-5629fc99f9f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ],
      "source": [
        "flatten = nn.Flatten()  # initialise the flatten module\n",
        "flat_image = flatten(\n",
        "    input_minibatch\n",
        ")  # pass the input minibatch through the initialised module\n",
        "print(flat_image.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN94eOX1okRh"
      },
      "source": [
        "### nn.Linear\n",
        "\n",
        "`nn.Linear` represents a fully-connected layer. It takes an input vector and computes an output by multiplying it with a weight matrix and then adding a bias.\n",
        "\n",
        "In other words, it performs the transformation:\n",
        "$\\text{output} = W \\cdot \\text{input} + b$\n",
        "\n",
        "This allows the model to learn how different input features contribute to the prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Ewd1lIoecJ",
        "outputId": "576cdcb1-d0ae-47c3-9e17-de16be5ed46f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 512])\n"
          ]
        }
      ],
      "source": [
        "layer1 = nn.Linear(in_features=28 * 28, out_features=512)  # initialise the linear layer\n",
        "hidden1 = layer1(\n",
        "    flat_image\n",
        ")  # pass the output from previous flatten layer through the linear layer\n",
        "print(hidden1.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uH_hKCCpIr0"
      },
      "source": [
        "### nn.ReLU\n",
        "\n",
        "Activation functions add non-linearity to the model, which allows neural networks\n",
        "to learn complex patterns. If we only stacked linear layers, the entire model\n",
        "would still behave like a single linear transformation. Adding non-linear\n",
        "activations between layers is what enables deep networks to model richer\n",
        "relationships.\n",
        "\n",
        "`nn.ReLU` (Rectified Linear Unit) sets all negative values to zero and keeps the\n",
        "positive values unchanged. It is simple efficient, and widely used in modern\n",
        "neural networks.\n",
        "\n",
        "There are other activation functions such as `nn.Sigmoid` and `nn.Tanh`, but\n",
        "ReLU is often preferred because it trains faster and reduces gradient issues\n",
        "in deep models.\n",
        "\n",
        "Read more: [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html), [nn.Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html), [nn.Tanh](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37f4kWoIoztq",
        "outputId": "648cc173-665e-4584-cdb3-1b35947fcfc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before ReLU: tensor([[ 0.1660,  0.1354, -0.1830,  ...,  0.0414, -0.5455,  0.1378],\n",
            "        [-0.0193,  0.0683, -0.2532,  ...,  0.1428, -0.3808,  0.0474],\n",
            "        [-0.0139, -0.0269, -0.2363,  ..., -0.1191, -0.3894,  0.3323]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.1660, 0.1354, 0.0000,  ..., 0.0414, 0.0000, 0.1378],\n",
            "        [0.0000, 0.0683, 0.0000,  ..., 0.1428, 0.0000, 0.0474],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3323]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "relu = nn.ReLU()\n",
        "hidden1 = relu(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")\n",
        "\n",
        "# TODO:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ðŸš© Note:\n",
        "> Notice what happened to the negative values in the input before they are passed through ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRAoOyPjqqTg"
      },
      "source": [
        "### nn.Sequential\n",
        "\n",
        "`nn.Sequential` is an **ordered** container that lets you combine multiple layers\n",
        "into a single module. When an input is passed to a `Sequential` block, it flows\n",
        "through each layer in the exact order they are listed.\n",
        "\n",
        "This is useful for defining simple feed-forward architectures, where the computation\n",
        "happens step-by-step without branching. It allows you to treat several layers\n",
        "as one logical **building block** in your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2OVqUf_qaQU",
        "outputId": "aa7ca1b0-b8bf-4934-d092-b1a164bb335b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input mini batch: torch.Size([3, 28, 28])\n",
            "Logits: torch.Size([3, 10])\n"
          ]
        }
      ],
      "source": [
        "block1 = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(28 * 28, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 10),\n",
        ")\n",
        "\n",
        "input_image = torch.rand(3, 28, 28)\n",
        "print(f\"Input mini batch: {input_image.size()}\")\n",
        "logits = block1(input_image)\n",
        "print(f\"Logits: {logits.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gZyZOHcruCN"
      },
      "source": [
        "### nn.Softmax\n",
        "\n",
        "The last linear layer of the neural network returns **logits** - raw, unnormalised\n",
        "scores that can take any real value. To convert these logits into class\n",
        "probabilities, we apply the `nn.Softmax` function.\n",
        "\n",
        "Softmax exponentiates and normalises the logits so that:\n",
        "- All output values are in the range [0, 1]\n",
        "- The values across the chosen dimension sum to 1\n",
        "\n",
        "This produces a probability distribution over the classes.\n",
        "\n",
        "`dim` parameter indicates the axis along which the values should sum to 1.\n",
        "\n",
        "Formula:\n",
        "\n",
        "$\\text{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_j e^{z_j}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT1HMvWZrf6F",
        "outputId": "a2e02852-7080-4468-f4f5-12fdd2712d15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logits\n",
            "tensor([[ 0.0202,  0.0906,  0.0287, -0.0070,  0.0809, -0.0180,  0.0154,  0.0121,\n",
            "         -0.1479,  0.0283],\n",
            "        [ 0.0036, -0.0100,  0.0729, -0.0134,  0.0255,  0.0444, -0.0113,  0.0276,\n",
            "         -0.1044, -0.0367],\n",
            "        [ 0.0404,  0.0026,  0.0313, -0.0133,  0.0349, -0.0144,  0.0375, -0.0126,\n",
            "         -0.1170, -0.0841]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Predicted probabilities\n",
            "tensor([[0.1008, 0.1082, 0.1017, 0.0981, 0.1071, 0.0970, 0.1003, 0.1000, 0.0852,\n",
            "         0.1016],\n",
            "        [0.1003, 0.0989, 0.1075, 0.0986, 0.1025, 0.1044, 0.0988, 0.1027, 0.0900,\n",
            "         0.0963],\n",
            "        [0.1050, 0.1011, 0.1040, 0.0995, 0.1044, 0.0994, 0.1047, 0.0996, 0.0897,\n",
            "         0.0927]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ],
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probabilities = softmax(logits)\n",
        "print(f\"Logits\\n{logits}\\n\")\n",
        "print(f\"Predicted probabilities\\n{pred_probabilities}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNvcI0Du3U6F"
      },
      "source": [
        "# ðŸš© Mini Challenge\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/ntu-dl-bootcamp/deep-learning-2026/raw/main/SESSION2/mini-challenge-session-2.png\" width=\"600\">\n",
        "</p>\n",
        "\n",
        "**Your Task:**\n",
        "\n",
        "1. Implement the neural network architecture shown in the image (using `nn.Module` in PyTorch).\n",
        "2. Train the network using reasonable hyperparameters (e.g., learning rate, batch size, number of epochs).\n",
        "3. Compare its performance (accuracy/loss) with the previous model you built."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # TODO: Define the layers here\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Define the forward pass here\n",
        "        return logits\n",
        "\n",
        "\n",
        "model = NeuralNetwork().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIxBFWs0uAER"
      },
      "source": [
        "# Optimizing the Model's Parameters\n",
        "\n",
        "Once we have a model and data, the next step is to **train** the model by adjusting its parameters so that its predictions improve.\n",
        "\n",
        "Training is an **iterative** process. In each iteration:\n",
        "\n",
        "1. The model **makes a prediction**.\n",
        "2. We **measure the error** using a **loss function**.\n",
        "3. We compute how the error **changes with respect to each parameter** (this is done automatically by PyTorch using **backpropagation**).\n",
        "4. We **update the parameters** to reduce the error (using **gradient descent** or a variant of it)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model parameters\n",
        "\n",
        "Many layers inside a neural network are parameterised. This means that they have associated weights and biases that are optimised during training.\n",
        "\n",
        "`nn.Module` tracks all the parameters inside a model object. This can be accessed using the model's `parameters()` and `named_parameters()` methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model structure: NeuralNetwork()\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This loop helps us inspect the parameters (weights and biases) of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([256, 784]) | Values : tensor([[ 3.3471e-02,  8.9448e-05, -2.8074e-02,  ..., -8.5677e-03,\n",
            "         -2.9638e-02,  2.5180e-02],\n",
            "        [-6.5901e-03, -8.7653e-03,  1.3903e-02,  ..., -1.1927e-02,\n",
            "         -2.7254e-02, -2.6111e-02]], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([256]) | Values : tensor([0.0091, 0.0328], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([128, 256]) | Values : tensor([[ 0.0298,  0.0023, -0.0261,  0.0107, -0.0027, -0.0109, -0.0017,  0.0210,\n",
            "          0.0399, -0.0341, -0.0353, -0.0597, -0.0352,  0.0190, -0.0362,  0.0116,\n",
            "         -0.0331, -0.0167, -0.0087, -0.0381, -0.0160,  0.0381,  0.0333, -0.0514,\n",
            "          0.0054, -0.0367, -0.0616,  0.0479, -0.0342, -0.0502, -0.0525, -0.0377,\n",
            "         -0.0017, -0.0251, -0.0138,  0.0353,  0.0343, -0.0417,  0.0325, -0.0391,\n",
            "         -0.0297,  0.0198,  0.0124,  0.0469, -0.0170,  0.0480, -0.0191,  0.0208,\n",
            "          0.0588,  0.0156, -0.0376,  0.0378, -0.0059, -0.0449, -0.0354, -0.0439,\n",
            "         -0.0124,  0.0212,  0.0247, -0.0516, -0.0447, -0.0490, -0.0377, -0.0260,\n",
            "         -0.0360,  0.0434,  0.0285, -0.0044, -0.0322, -0.0173, -0.0024, -0.0432,\n",
            "         -0.0016,  0.0556, -0.0327, -0.0535, -0.0295,  0.0553, -0.0421,  0.0146,\n",
            "         -0.0541,  0.0247, -0.0425,  0.0537, -0.0365,  0.0514, -0.0330, -0.0121,\n",
            "          0.0227, -0.0009,  0.0386, -0.0561,  0.0311, -0.0043, -0.0426, -0.0582,\n",
            "          0.0008, -0.0254,  0.0146,  0.0252, -0.0500, -0.0009,  0.0554, -0.0042,\n",
            "         -0.0556,  0.0089, -0.0238, -0.0113, -0.0491, -0.0482, -0.0229,  0.0228,\n",
            "         -0.0212,  0.0524, -0.0622,  0.0061,  0.0373,  0.0579, -0.0597, -0.0543,\n",
            "         -0.0360, -0.0147,  0.0250, -0.0288, -0.0567, -0.0585, -0.0508, -0.0113,\n",
            "          0.0294, -0.0204, -0.0224, -0.0149, -0.0077,  0.0540,  0.0287, -0.0333,\n",
            "         -0.0534, -0.0225,  0.0418,  0.0570,  0.0615,  0.0244,  0.0571, -0.0327,\n",
            "          0.0227, -0.0258, -0.0140,  0.0608, -0.0481, -0.0358,  0.0399, -0.0215,\n",
            "         -0.0336, -0.0509, -0.0506, -0.0561,  0.0463, -0.0028,  0.0094, -0.0103,\n",
            "         -0.0445,  0.0303, -0.0608,  0.0356, -0.0488, -0.0377, -0.0057,  0.0314,\n",
            "         -0.0217,  0.0614, -0.0177, -0.0582, -0.0173,  0.0091, -0.0265,  0.0301,\n",
            "          0.0032,  0.0408,  0.0049, -0.0304, -0.0484,  0.0514,  0.0061, -0.0468,\n",
            "         -0.0087, -0.0420, -0.0441,  0.0625, -0.0026, -0.0052, -0.0181,  0.0594,\n",
            "          0.0291, -0.0486, -0.0516, -0.0027, -0.0066,  0.0597,  0.0493,  0.0557,\n",
            "         -0.0191,  0.0128,  0.0204, -0.0283,  0.0085,  0.0537,  0.0020, -0.0278,\n",
            "          0.0350, -0.0526,  0.0444,  0.0402,  0.0617, -0.0614,  0.0501, -0.0205,\n",
            "         -0.0364, -0.0526,  0.0493,  0.0405,  0.0032, -0.0003,  0.0504,  0.0419,\n",
            "          0.0559,  0.0145, -0.0043,  0.0250,  0.0237,  0.0348, -0.0489,  0.0194,\n",
            "         -0.0325, -0.0292,  0.0415, -0.0444, -0.0611, -0.0208, -0.0423,  0.0143,\n",
            "          0.0006, -0.0625, -0.0075,  0.0461,  0.0062,  0.0150,  0.0220, -0.0350,\n",
            "          0.0351, -0.0170, -0.0542,  0.0532,  0.0447, -0.0071, -0.0146,  0.0158],\n",
            "        [-0.0095, -0.0117, -0.0012,  0.0339, -0.0020,  0.0425, -0.0228,  0.0575,\n",
            "         -0.0335, -0.0320, -0.0161,  0.0183, -0.0129,  0.0601, -0.0075, -0.0258,\n",
            "          0.0331,  0.0348,  0.0289,  0.0189, -0.0495, -0.0138,  0.0590,  0.0615,\n",
            "         -0.0507, -0.0142, -0.0167, -0.0236, -0.0449, -0.0059, -0.0575,  0.0451,\n",
            "         -0.0587,  0.0588, -0.0017, -0.0582, -0.0524, -0.0270, -0.0437, -0.0437,\n",
            "          0.0560, -0.0081,  0.0623,  0.0432,  0.0546, -0.0176, -0.0571,  0.0277,\n",
            "         -0.0567,  0.0253, -0.0601, -0.0290, -0.0271, -0.0389, -0.0304,  0.0424,\n",
            "          0.0391, -0.0622, -0.0308,  0.0226, -0.0072, -0.0275,  0.0232, -0.0623,\n",
            "         -0.0436, -0.0166, -0.0462,  0.0049, -0.0136,  0.0603,  0.0567,  0.0416,\n",
            "         -0.0602, -0.0525, -0.0596, -0.0267, -0.0369, -0.0185, -0.0227,  0.0332,\n",
            "         -0.0515,  0.0569,  0.0193, -0.0406, -0.0505,  0.0555, -0.0081,  0.0357,\n",
            "          0.0162, -0.0181,  0.0540,  0.0391,  0.0608, -0.0160, -0.0058, -0.0277,\n",
            "          0.0126,  0.0085, -0.0103,  0.0329,  0.0225, -0.0607, -0.0286,  0.0407,\n",
            "         -0.0429,  0.0573,  0.0459, -0.0539,  0.0294,  0.0021,  0.0554,  0.0311,\n",
            "         -0.0101, -0.0389,  0.0384,  0.0276, -0.0556,  0.0526, -0.0403,  0.0127,\n",
            "          0.0369, -0.0077,  0.0196,  0.0383,  0.0595,  0.0377, -0.0014, -0.0361,\n",
            "          0.0201, -0.0195,  0.0356,  0.0042,  0.0482,  0.0121, -0.0094, -0.0166,\n",
            "          0.0261, -0.0163, -0.0331,  0.0137, -0.0511,  0.0265, -0.0431, -0.0609,\n",
            "          0.0418,  0.0161, -0.0541, -0.0145, -0.0111,  0.0143, -0.0620,  0.0047,\n",
            "         -0.0110,  0.0428,  0.0374,  0.0195, -0.0185,  0.0232, -0.0562, -0.0611,\n",
            "          0.0069, -0.0236,  0.0256, -0.0124, -0.0325,  0.0542, -0.0540,  0.0100,\n",
            "          0.0280,  0.0133, -0.0214,  0.0138,  0.0061, -0.0133,  0.0564,  0.0594,\n",
            "          0.0442, -0.0354,  0.0190, -0.0206, -0.0246,  0.0227, -0.0423,  0.0548,\n",
            "         -0.0241, -0.0618, -0.0410, -0.0573,  0.0518, -0.0506, -0.0006, -0.0354,\n",
            "          0.0358,  0.0350, -0.0591,  0.0568,  0.0347,  0.0314, -0.0446,  0.0586,\n",
            "          0.0255, -0.0425,  0.0488, -0.0621,  0.0495,  0.0215,  0.0167, -0.0427,\n",
            "          0.0053, -0.0302,  0.0246, -0.0212, -0.0401, -0.0296,  0.0185,  0.0151,\n",
            "          0.0311, -0.0175, -0.0502, -0.0185,  0.0558, -0.0154, -0.0081, -0.0185,\n",
            "         -0.0291, -0.0572, -0.0294, -0.0382,  0.0027, -0.0516,  0.0543, -0.0251,\n",
            "          0.0118,  0.0337,  0.0440,  0.0468,  0.0585, -0.0216, -0.0441,  0.0205,\n",
            "          0.0527,  0.0297, -0.0586,  0.0050,  0.0308, -0.0030,  0.0537, -0.0565,\n",
            "         -0.0059,  0.0463,  0.0040, -0.0468, -0.0454, -0.0577, -0.0222, -0.0530]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([128]) | Values : tensor([-0.0512, -0.0549], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 128]) | Values : tensor([[ 0.0782,  0.0620,  0.0521, -0.0545,  0.0084,  0.0370, -0.0638, -0.0640,\n",
            "          0.0279,  0.0767, -0.0022, -0.0332, -0.0710,  0.0159,  0.0434, -0.0599,\n",
            "         -0.0834, -0.0452, -0.0608, -0.0455,  0.0512,  0.0439,  0.0750,  0.0563,\n",
            "          0.0274,  0.0749, -0.0806, -0.0078,  0.0248,  0.0692, -0.0173, -0.0132,\n",
            "         -0.0579, -0.0544,  0.0267,  0.0204, -0.0690,  0.0071,  0.0556,  0.0596,\n",
            "          0.0844, -0.0413,  0.0135, -0.0542, -0.0622,  0.0340,  0.0247,  0.0812,\n",
            "          0.0212,  0.0469, -0.0407,  0.0501,  0.0813,  0.0717,  0.0064,  0.0424,\n",
            "          0.0124,  0.0806, -0.0627,  0.0581, -0.0197, -0.0615,  0.0823,  0.0130,\n",
            "         -0.0539, -0.0841,  0.0028,  0.0517,  0.0829, -0.0251,  0.0401, -0.0106,\n",
            "          0.0628, -0.0544, -0.0091,  0.0493,  0.0416,  0.0461,  0.0096, -0.0511,\n",
            "         -0.0173,  0.0817, -0.0149, -0.0827,  0.0690, -0.0799,  0.0444,  0.0289,\n",
            "          0.0311, -0.0510, -0.0386,  0.0269, -0.0377,  0.0063, -0.0295, -0.0490,\n",
            "          0.0628,  0.0640, -0.0195, -0.0449, -0.0124, -0.0726,  0.0438,  0.0329,\n",
            "          0.0832,  0.0868,  0.0148, -0.0484,  0.0676, -0.0791, -0.0844,  0.0101,\n",
            "          0.0161,  0.0371, -0.0792, -0.0168,  0.0688,  0.0258, -0.0634, -0.0491,\n",
            "          0.0696,  0.0247,  0.0796,  0.0014,  0.0853,  0.0685, -0.0696,  0.0850],\n",
            "        [-0.0384,  0.0499,  0.0339,  0.0051, -0.0639, -0.0644, -0.0105,  0.0636,\n",
            "         -0.0249, -0.0558,  0.0223,  0.0822,  0.0134,  0.0465,  0.0112,  0.0502,\n",
            "         -0.0435,  0.0317, -0.0564,  0.0193,  0.0185, -0.0625, -0.0555, -0.0506,\n",
            "          0.0715,  0.0707,  0.0251, -0.0375, -0.0765, -0.0778,  0.0048,  0.0866,\n",
            "          0.0880,  0.0124,  0.0881, -0.0309, -0.0508, -0.0480, -0.0364,  0.0389,\n",
            "          0.0825, -0.0568,  0.0404,  0.0266,  0.0402,  0.0037, -0.0088, -0.0628,\n",
            "          0.0352,  0.0667,  0.0720,  0.0013,  0.0028, -0.0047,  0.0702,  0.0047,\n",
            "          0.0809,  0.0274, -0.0638, -0.0582, -0.0518,  0.0838,  0.0739,  0.0165,\n",
            "         -0.0545,  0.0656, -0.0021, -0.0308,  0.0626, -0.0371, -0.0369, -0.0389,\n",
            "          0.0370,  0.0198, -0.0389,  0.0346,  0.0289,  0.0319,  0.0616,  0.0308,\n",
            "          0.0043, -0.0529, -0.0381,  0.0466, -0.0116,  0.0608, -0.0683,  0.0431,\n",
            "         -0.0733, -0.0028,  0.0084,  0.0661,  0.0381, -0.0719,  0.0636,  0.0669,\n",
            "          0.0669, -0.0581,  0.0679,  0.0091, -0.0139, -0.0303, -0.0408, -0.0115,\n",
            "         -0.0646,  0.0760,  0.0075,  0.0543,  0.0037,  0.0038,  0.0502, -0.0719,\n",
            "          0.0707,  0.0075, -0.0787,  0.0279,  0.0353, -0.0532,  0.0765,  0.0383,\n",
            "          0.0335, -0.0589, -0.0470, -0.0839, -0.0009,  0.0045, -0.0299,  0.0851]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0824,  0.0669], grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "rgzqm7J0teHU"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameters\n",
        "\n",
        "**Hyperparameters** are settings that control how the training process behaves.  \n",
        "They are **not** learned by the model â€” we choose them manually.\n",
        "\n",
        "Key hyperparameters we will use:\n",
        "\n",
        "1. **Number of epochs**  \n",
        "   How many times we go through the entire training dataset.\n",
        "\n",
        "2. **Batch size**  \n",
        "   How many samples the model sees **before** the parameters are updated.\n",
        "\n",
        "3. **Learning rate**  \n",
        "   How big the parameter update step is during optimization. \n",
        "\n",
        "Choosing good hyperparameters is important for effective learning and stable convergence.\n",
        "\n",
        "\n",
        "> ðŸš© Question:\n",
        ">\n",
        "> How might changing the learning rate affect the training process?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16v62WF2vvUB"
      },
      "source": [
        "## Optimisation loop\n",
        "Using these hyperparamters, we can train and optimise the paramters of our model with an optimisation loop. Each iteration of the optimisation loop is called as an **epoch**.\n",
        "\n",
        "Each epoch has two parts\n",
        "1. Iterate over the training loop and update the parameters\n",
        "2. Iterate over the test / validation loop and check if the model's performance is improving.\n",
        "\n",
        "Two important concepts used in the training loop are the loss function and the optimizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp1EmysNw0_V"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "When our network is first initialized, its predictions will usually be incorrect.  \n",
        "A **loss function** tells us *how far off* the modelâ€™s predictions are from the true labels.  \n",
        "During training, we aim to **minimize this loss**.\n",
        "\n",
        "To compute the loss:\n",
        "1. The model makes a **prediction** from the input.\n",
        "2. The prediction is **compared with the true label**.\n",
        "3. The loss function outputs a **single number** representing the error.\n",
        "\n",
        "### Common Loss Functions\n",
        "\n",
        "| Loss Function | Use Case | Notes |\n",
        "|--------------|----------|-------|\n",
        "| **`nn.MSELoss`** | Regression tasks | Measures squared difference between prediction and target. |\n",
        "| **`nn.NLLLoss`** | Classification | Works with log-probabilities. |\n",
        "| **`nn.CrossEntropyLoss`** | Classification | Combines `LogSoftmax` + `NLLLoss`. Works directly on raw logits. |\n",
        "\n",
        "We will use **`nn.CrossEntropyLoss`**, which:\n",
        "- Takes the modelâ€™s raw outputs (**logits**),\n",
        "- Applies the appropriate normalization internally,\n",
        "- Computes how wrong the prediction is.\n",
        "\n",
        "This makes it well-suited for multi-class classification problems like MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "uCwdivyPvtU-"
      },
      "outputs": [],
      "source": [
        "# initialise the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUTADFRRyDPh"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "**Optimization** is the process of adjusting the modelâ€™s parameters so that the loss decreases over time.\n",
        "\n",
        "An **optimizer** defines *how* these parameter updates are performed.\n",
        "\n",
        "In our example, we use **Stochastic Gradient Descent (SGD)**, but PyTorch provides many others such as **Adam** and **RMSProp**, which may work better depending on the task.\n",
        "\n",
        "To create an optimizer, we:\n",
        "1. **Pass in the modelâ€™s parameters** (so the optimizer knows what to update)\n",
        "2. Set the **learning rate** (to control how big each update step is)\n",
        "\n",
        "Once defined, the optimizer will handle the parameter updates during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "PVZHgyi1x96X"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eP1Jmy_ygVu"
      },
      "source": [
        "### Inside the training loop\n",
        "The optimizer updates the model parameters in **three steps**:\n",
        "\n",
        "1. **Reset the gradients**\n",
        "\n",
        "    Gradients accumulate by default in PyTorch. We reset them each iteration to avoid carrying over values from the previous update\n",
        "\n",
        "    ```python\n",
        "    optimizer.zero_grad()\n",
        "    ```\n",
        "\n",
        "2. **Backpropagate the loss**\n",
        "\n",
        "    This computes how the loss changes with respect to each model parameter and stores the gradients.\n",
        "\n",
        "    ```python\n",
        "    loss.backward()\n",
        "    ```\n",
        "\n",
        "3. **Update the parameters**\n",
        "\n",
        "    The optimizer adjusts the parameters using the computed gradients (e.g., gradient descent).\n",
        "\n",
        "    ```python\n",
        "    optimizer.step()\n",
        "    ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va8teUI_yv3P"
      },
      "source": [
        "## Full training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "k0vXWA8nyZ0D"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute the prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2GpV7NVzYGd"
      },
      "source": [
        "## Full testing loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "qB4TaHEKzVvu"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode - important for batch normalisation and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.inference_mode():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(\n",
        "        f\"Performance on the test set:\\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2w54rd80AXO"
      },
      "source": [
        "We initialize the loss function and optimizer, and pass it to train_loop and test_loop. Feel free to increase the number of epochs to track the modelâ€™s improving performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xJvDE0Ez69a",
        "outputId": "2cc58c97-0e6a-4977-e3cb-b8706fe06a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.308231  [   64/60000]\n",
            "loss: 2.299742  [ 6464/60000]\n",
            "loss: 2.286734  [12864/60000]\n",
            "loss: 2.285746  [19264/60000]\n",
            "loss: 2.299892  [25664/60000]\n",
            "loss: 2.264055  [32064/60000]\n",
            "loss: 2.274684  [38464/60000]\n",
            "loss: 2.288671  [44864/60000]\n",
            "loss: 2.268831  [51264/60000]\n",
            "loss: 2.270002  [57664/60000]\n",
            "Performance on the test set:\n",
            " Accuracy: 37.5%, Avg loss: 2.265120 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.266929  [   64/60000]\n",
            "loss: 2.257928  [ 6464/60000]\n",
            "loss: 2.272660  [12864/60000]\n",
            "loss: 2.250406  [19264/60000]\n",
            "loss: 2.242848  [25664/60000]\n",
            "loss: 2.241465  [32064/60000]\n",
            "loss: 2.238936  [38464/60000]\n",
            "loss: 2.213497  [44864/60000]\n",
            "loss: 2.209754  [51264/60000]\n",
            "loss: 2.221828  [57664/60000]\n",
            "Performance on the test set:\n",
            " Accuracy: 50.8%, Avg loss: 2.211725 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.218850  [   64/60000]\n",
            "loss: 2.194891  [ 6464/60000]\n",
            "loss: 2.207536  [12864/60000]\n",
            "loss: 2.161048  [19264/60000]\n",
            "loss: 2.160557  [25664/60000]\n",
            "loss: 2.160926  [32064/60000]\n",
            "loss: 2.163658  [38464/60000]\n",
            "loss: 2.139392  [44864/60000]\n",
            "loss: 2.154218  [51264/60000]\n",
            "loss: 2.073610  [57664/60000]\n",
            "Performance on the test set:\n",
            " Accuracy: 55.4%, Avg loss: 2.125558 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.155226  [   64/60000]\n",
            "loss: 2.117643  [ 6464/60000]\n",
            "loss: 2.126180  [12864/60000]\n",
            "loss: 2.072977  [19264/60000]\n",
            "loss: 2.094388  [25664/60000]\n",
            "loss: 2.047299  [32064/60000]\n",
            "loss: 2.101761  [38464/60000]\n",
            "loss: 2.074739  [44864/60000]\n",
            "loss: 2.001944  [51264/60000]\n",
            "loss: 2.018235  [57664/60000]\n",
            "Performance on the test set:\n",
            " Accuracy: 62.5%, Avg loss: 1.986856 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.918509  [   64/60000]\n",
            "loss: 1.916034  [ 6464/60000]\n",
            "loss: 1.984017  [12864/60000]\n",
            "loss: 1.981318  [19264/60000]\n",
            "loss: 1.881136  [25664/60000]\n",
            "loss: 1.860844  [32064/60000]\n",
            "loss: 1.886369  [38464/60000]\n",
            "loss: 1.851172  [44864/60000]\n",
            "loss: 1.807441  [51264/60000]\n",
            "loss: 1.770894  [57664/60000]\n",
            "Performance on the test set:\n",
            " Accuracy: 69.6%, Avg loss: 1.779460 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.803741  [   64/60000]\n",
            "loss: 1.831293  [ 6464/60000]\n",
            "loss: 1.669698  [12864/60000]\n",
            "loss: 1.698165  [19264/60000]\n",
            "loss: 1.684910  [25664/60000]\n",
            "loss: 1.639296  [32064/60000]\n",
            "loss: 1.556679  [38464/60000]\n",
            "loss: 1.576540  [44864/60000]\n",
            "loss: 1.638127  [51264/60000]\n",
            "loss: 1.576248  [57664/60000]\n",
            "Performance on the test set:\n",
            " Accuracy: 73.7%, Avg loss: 1.503119 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.521192  [   64/60000]\n",
            "loss: 1.458760  [ 6464/60000]\n",
            "loss: 1.570758  [12864/60000]\n",
            "loss: 1.399807  [19264/60000]\n",
            "loss: 1.440654  [25664/60000]\n",
            "loss: 1.432544  [32064/60000]\n",
            "loss: 1.355046  [38464/60000]\n",
            "loss: 1.411492  [44864/60000]\n",
            "loss: 1.420904  [51264/60000]\n",
            "loss: 1.149757  [57664/60000]\n",
            "Performance on the test set:\n",
            " Accuracy: 77.1%, Avg loss: 1.211623 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.180397  [   64/60000]\n",
            "loss: 1.260052  [ 6464/60000]\n",
            "loss: 1.321445  [12864/60000]\n",
            "loss: 1.186217  [19264/60000]\n",
            "loss: 1.129807  [25664/60000]\n",
            "loss: 1.136561  [32064/60000]\n",
            "loss: 1.076199  [38464/60000]\n",
            "loss: 0.934264  [44864/60000]\n",
            "loss: 1.052644  [51264/60000]\n",
            "loss: 0.998091  [57664/60000]\n",
            "Performance on the test set:\n",
            " Accuracy: 79.5%, Avg loss: 0.983300 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.894908  [   64/60000]\n",
            "loss: 0.954108  [ 6464/60000]\n",
            "loss: 1.165254  [12864/60000]\n",
            "loss: 0.894249  [19264/60000]\n",
            "loss: 0.988552  [25664/60000]\n",
            "loss: 1.002840  [32064/60000]\n",
            "loss: 0.793000  [38464/60000]\n",
            "loss: 0.849387  [44864/60000]\n",
            "loss: 0.738075  [51264/60000]\n",
            "loss: 0.927252  [57664/60000]\n",
            "Performance on the test set:\n",
            " Accuracy: 81.0%, Avg loss: 0.829596 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.886011  [   64/60000]\n",
            "loss: 0.747613  [ 6464/60000]\n",
            "loss: 0.835960  [12864/60000]\n",
            "loss: 0.657473  [19264/60000]\n",
            "loss: 0.851647  [25664/60000]\n",
            "loss: 0.812140  [32064/60000]\n",
            "loss: 0.723491  [38464/60000]\n",
            "loss: 0.758241  [44864/60000]\n",
            "loss: 0.776429  [51264/60000]\n",
            "loss: 0.869810  [57664/60000]\n",
            "Performance on the test set:\n",
            " Accuracy: 82.2%, Avg loss: 0.725502 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "YaiHC_ee0Mxw",
        "outputId": "56d0e4f9-9507-4c57-9e9a-3c20176329b0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 4\n",
            "\n",
            "Predicted class: tensor([4])\n"
          ]
        }
      ],
      "source": [
        "img, label = training_data[20]\n",
        "\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\\n\")\n",
        "\n",
        "img = img.to(device)\n",
        "logits = model(img)\n",
        "predicted_probabilities = nn.Softmax(dim=1)(logits)\n",
        "predicted_class = torch.argmax(predicted_probabilities, dim=1)\n",
        "print(f\"Predicted class: {predicted_class}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-0zo4un1oGq"
      },
      "source": [
        "# Save and load the model\n",
        "\n",
        "PyTorch models store the learned parameters in an internal state dictionary, called state_dict. **These can be saved using the torch.save method.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "BEisYOlX1ewU"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model_weights.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPMoBfgc18Nd"
      },
      "source": [
        "To load model weights, you need to create an instance of the same model first, and then load the parameters using `load_state_dict()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsM4JHMy13oH",
        "outputId": "4c8a287c-bed1-4dd2-88cd-8de095157719"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_new = NeuralNetwork().to(device)\n",
        "\n",
        "model_new.load_state_dict(torch.load(\"model_weights.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "kARmbf6s2LWJ",
        "outputId": "09a37dc3-7a40-436d-e95d-50c02d3c2040"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 4\n",
            "\n",
            "Predicted class: tensor([4])\n"
          ]
        }
      ],
      "source": [
        "# Testing the newly loaded model, `model_new`\n",
        "\n",
        "img, label = training_data[20]\n",
        "\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\\n\")\n",
        "\n",
        "img = img.to(device)\n",
        "logits = model_new(img)\n",
        "predicted_probabilities = nn.Softmax(dim=1)(logits)\n",
        "predicted_class = torch.argmax(predicted_probabilities, dim=1)\n",
        "print(f\"Predicted class: {predicted_class}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCKMg_VuDY1M"
      },
      "source": [
        "# Recommended Reading and Other Resources\n",
        "1. [What is torch.nn really?](https://pytorch.org/tutorials/beginner/nn_tutorial.html)\n",
        "2. [PyTorch Beginner Series](https://www.youtube.com/playlist?list=PL_lsbAsL_o2CTlGHgMxNrKhzP97BaG9ZN)\n",
        "\n",
        "This notebook is based on [Learn the Basics](https://pytorch.org/tutorials/beginner/basics/intro.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "subcortical-seg-cnn-atlas",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
